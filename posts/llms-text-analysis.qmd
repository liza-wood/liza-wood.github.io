---
title: "LLMs for text analysis"
subtitle: "Research with the OpenAI API"
author: "Liza Wood"
date: "August 15 2025"
description: ""
type: post
toc: TRUE
---

```{r, echo = F, results = F}
knitr::opts_chunk$set(
  echo = T, warning = F,  error = F, message = F)
```

# Introduction: What is a Large Language Model?  

Talk about Artificial Intelligence is everywhere. From [university teaching](https://www.nytimes.com/2025/05/14/technology/chatgpt-college-professors.html), [student essays](https://www.timeshighereducation.com/news/nine-10-uk-undergraduates-now-using-ai-assessments-survey#:~:text=The%20survey%20found%20that%20the,near%2Duniversal%20by%20next%20year), [academic research](https://onlinelibrary.wiley.com/doi/abs/10.1111/psj.70034), [regulatory consultations](https://www.theguardian.com/technology/2025/may/14/uk-government-ai-consult-consultation), and even a whole array of unnecessary appliances like [toothbrushes](https://www.oralb.co.uk/en-gb/product-collections/genius-x). 

This post is about AI, and more specifically, Machine Learning (ML) in research. To be self-referential, [claude.ai](claude.ai) generated this overview of different ML methods and how they relate. ML covers a wide array of approaches for computer prediction based on 'learning' (i.e. giving the computer data). Learning is usually classified into three types: Supervised, Unsupervised, and Reinforcement. 

![Overview of machine learning concepts, generated by claude.ai](posts/img/ML-overview.png)

In each of these categories, the figure highlights that various statistical methods that have been around for quite a while fall under the ML umbrella, such as statistical regression (supervised) and Principle Component Analysis (unsupervised). But beyond these traditional approaches, each of these types of learning can use 'neural networks' for deep learning.

Neural networks -- computational models inspired by neural networks in biology -- are typically 'trained' (supervised) on data so that it learns how to minimize the difference in the output and the values in the training dataset. One popular software for implementing neural networks is (Keras.io)[https://keras.io/], allowing researchers to train and develop their own predictive models. 

The 'transformer' architecture behind models like ChatGPT and Claude has evolved from these sorts of neural networks (but critically, rely on a 'self-attention mechanism' to predict word sequence). And after being trained on massive amounts of text^[In fact, [OpenAI is in a lawsuit with the _New York Times_](https://www.npr.org/2023/12/27/1221821750/new-york-times-sues-chatgpt-openai-microsoft-for-copyright-infringement) for copyright infringement, namely using copyrighted data to train its models. One main critique of LLMs then, is that they has taken text -- both from private (copyrighted) and public (internet forums, blogs, etc) sources -- and is now capitalizing on this incredible, arguably illegal, enclosure.], the resulting Large Language Models (LLMs) are what we can chat with in either an unsupervised fashion (open chats) or supervised fashion (LLMs that are tuned to specific tasks).

## LLMs in research 

Now that LLMs have already been trained on huge amounts of data, researchers are able to leverage the learning that has already been done to help assist with research tasks. Researchers are using LLMs in a variety of ways, ranging from synthesizing social data to generating research ideas.

This post is specifically about text classification (and sometimes interpretation) -- reading a text and grouping the text according to a decision criteria, or extracting some feature of the text. 

# APIs versus chat interfaces 


This presentation I shared with my research group, 'Reflections of text classification and OpenAI's (Chat)GPT'

## API 

This is outlined in this paper. When researchers are using these models, they are, by and large, using the API

## ChatGPT 

I have not heard of any researchers

Why not?

* It doesn't scale well -- copy and paste, conversation limits, less control of parameter settings, harder to reproduce

# Working with the API

## Getting set up 

1. Visit https://platform.openai.com/
2. Sign up to create an account (or log in if you already have an account via ChatGPT) 
3. Navigate to your profile 
4. Members > Invite (will need to name your 'Organization')
5. Navigate to Projects > Create 
6. Add members to project
7. Within the project, navigate to API keys > Create new secret key 
8. Set up billing



"Projects are shared environments where teams can collaborate and share API resources. You can set custom rate limits and manage access to resources"

## Elements of the query

### Differen models 

### Temperature, top_p, and max_tokens 

Also maybe verbosity

### System instructions 

### User prompt 

### API key 

## Interfacing with the API 

```{r, eval = F}
body <- list(
  model = modelName,
  max_tokens = max_tokens,
  temperature = temperature,
  top_p = top_p,
  messages = list(list(
    # Adding role and content
    role = "system",
    content = instructions),
    # Then same as before
    list(role = "user", 
         content = prompt)
  ))
```

```{r, eval = F}
response <- POST(
  url = "https://api.openai.com/v1/chat/completions", 
  add_headers(Authorization = paste("Bearer", apiKey)),
  content_type_json(),
  encode = "json",
  body =  body
)
  
if(status_code(response)>200) {
  stop(content(response))
}
  
response <- content(response)
answer <- trimws(response$choices[[1]]$message$content)
```


## Scaling queries 

### Put it in a function

### Rate limits 

Tokens per minute, requests per minute

# Disclaimers 
* I am not an AI expert, and am only writing this post from the perspective of a computational social scientist who entered this space by way of analyzing text data. 

* On a similar note as above, OpenAI is [not, in fact, open](https://www.turing.ac.uk/blog/what-defines-open-open-ai). Despite its initial ideas of responsible and open AI, it has switched it model towards a capped for-profit model with exclusive contracts with Microsoft. Open source large language models are available on [Hugging Face](https://huggingface.co/).  
* I believe the integration of AI into online search engines is one more step towards the 'extractive and fragile monoculture' that is the modern internet, and divesting from big tech and re-wilding the internet is important for maintaining the internet commons (see '[We need to rewild the internet](https://www.noemamag.com/we-need-to-rewild-the-internet/)' by Farrell and Berjon).  
* The data servers that Generative AI depend on have large [environmental consequences](https://news.mit.edu/2025/explained-generative-ai-environmental-impact-0117). Though researchers have struggled to fully quantify this yet, it is clear that the costs of using AI often outweigh its benefits (i.e. something that could be searched in a classic search engine)